{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.3.0\n",
      "Keras version: 2.0.8\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "print(\"Keras version: {}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pos_tag(word):\n",
    "    return word.split('/')[0]\n",
    "\n",
    "regex = re.compile('[-+]?([0-9]+,)?[0-9]+.?[0-9]*')\n",
    "punctuation = re.compile('['+string.punctuation+']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data & create Lookup Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  26438\n",
      "Total number of unique words:  4939\n"
     ]
    }
   ],
   "source": [
    "raw_text = open(\"./data/wonderland.txt\").read()\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "words = raw_text.split()\n",
    "#words = [remove_pos_tag(word) for word in words if not regex.search(word)]\n",
    "#words = [word for word in words if not punctuation.search(word)]\n",
    "#words = words[:90000]\n",
    "vocab = sorted(list(set(words)))\n",
    "\n",
    "# Lookup tables\n",
    "word_to_int = dict((c, i) for i, c in enumerate(vocab))\n",
    "int_to_word = dict((i, c) for i, c in enumerate(vocab))\n",
    "\n",
    "print(\"Total number of words: \", len(words))\n",
    "print(\"Total number of unique words: \", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patterns:  26408\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 30\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(words) - seq_length):\n",
    "    seq_in = words[i:i + seq_length]\n",
    "    seq_out = words[i + seq_length]\n",
    "    dataX.append([word_to_int[word] for word in seq_in])\n",
    "    dataY.append(word_to_int[seq_out])\n",
    "\n",
    "print(\"Total number of patterns: \", len(dataX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she\n",
      "had\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([int_to_word[value] for value in dataX[0]]))\n",
    "print(int_to_word[dataY[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26408, 30, 1)\n",
      "(26408, 4939)\n"
     ]
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (len(dataX), seq_length, 1))\n",
    "\n",
    "# normalize\n",
    "X = X / float(len(vocab))\n",
    "print(X.shape)\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = keras.utils.to_categorical(dataY, len(vocab))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 30, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 30, 256)           264192    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4939)              1269323   \n",
      "=================================================================\n",
      "Total params: 2,058,827\n",
      "Trainable params: 2,058,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(X.shape[1], X.shape[2]))\n",
    "x = LSTM(256)(inp)\n",
    "x = Dropout(0.2)(x)\n",
    "output = Dense(y.shape[1], activation ='softmax')(x)\n",
    "\n",
    "generative_model = Model(inputs=inp, outputs=output)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "generative_model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "generative_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26408/26408 [==============================] - 264s - loss: 8.6734   \n",
      "Epoch 2/20\n",
      "26408/26408 [==============================] - 263s - loss: 9.0896   \n",
      "Epoch 3/20\n",
      "26408/26408 [==============================] - 263s - loss: 9.2051   \n",
      "Epoch 4/20\n",
      "26408/26408 [==============================] - 264s - loss: 9.2884   \n",
      "Epoch 5/20\n",
      "26408/26408 [==============================] - 263s - loss: 9.3297   \n",
      "Epoch 6/20\n",
      "26408/26408 [==============================] - 264s - loss: 9.3809   \n",
      "Epoch 7/20\n",
      "26408/26408 [==============================] - 265s - loss: 9.4258   \n",
      "Epoch 8/20\n",
      "26408/26408 [==============================] - 265s - loss: 9.4403   \n",
      "Epoch 9/20\n",
      "26408/26408 [==============================] - 264s - loss: 9.4480   \n",
      "Epoch 10/20\n",
      "26408/26408 [==============================] - 264s - loss: 9.4713   \n",
      "Epoch 11/20\n",
      "26408/26408 [==============================] - 265s - loss: 9.4841   \n",
      "Epoch 12/20\n",
      "26408/26408 [==============================] - 265s - loss: 9.4846   \n",
      "Epoch 13/20\n",
      "26408/26408 [==============================] - 264s - loss: 9.4966   \n",
      "Epoch 14/20\n",
      "26408/26408 [==============================] - 263s - loss: 9.5012   \n",
      "Epoch 15/20\n",
      "26408/26408 [==============================] - 264s - loss: 9.5066   \n",
      "Epoch 16/20\n",
      "26408/26408 [==============================] - 264s - loss: 9.5227   \n",
      "Epoch 17/20\n",
      "26408/26408 [==============================] - 264s - loss: 9.5303   \n",
      "Epoch 18/20\n",
      "26408/26408 [==============================] - 264s - loss: 9.5436   \n",
      "Epoch 19/20\n",
      "26408/26408 [==============================] - 263s - loss: 9.5403   \n",
      "Epoch 20/20\n",
      "26408/26408 [==============================] - 264s - loss: 9.5458   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a8102b4f98>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generative_model.fit(X, y, epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[362, 2809, 4391, 666, 2649, 622, 4721, 455, 2566, 4244, 4792, 506, 4669, 2397, 2272, 4368, 4391, 2094, 2340, 3649, 586, 2340, 4502, 362, 1093, 192, 2890, 1476, 506, 4754]\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "generated_text = []\n",
    "pattern = dataX[1000][:]\n",
    "\n",
    "print(pattern)\n",
    "\n",
    "# generate characters\n",
    "for i in range(15):\n",
    "    x = np.reshape(pattern, (1, seq_length, 1))\n",
    "    x = x / float(len(vocab))\n",
    "    prediction = generative_model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_word[index]\n",
    "    #print(result)\n",
    "    pattern.append(index)\n",
    "    generated_text.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4368, 4391, 2094, 2340, 3649, 586, 2340, 4502, 362, 1093, 192, 2890, 1476, 506, 4754, 4244, 4244, 4244, 4244, 4244, 4244, 4244, 4244, 4244, 4244, 4244, 4244, 4244, 4244, 4244]\n",
      "time to hear it say, as it turned a corner, 'oh my ears and whiskers, the the the the the the the the the the the the the the the\n",
      "the the the the the the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "print(pattern)\n",
    "print(' '.join([remove_pos_tag(int_to_word[value]) for value in pattern]))\n",
    "print(' '.join([remove_pos_tag(int_to_word[value]) for value in generated_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to implement temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107, 2733, 4725, 686, 2719, 2272, 1187, 297, 2240, 1483, 2348, 3622, 461, 62, 2251, 3622, 3020, 2272, 2865, 2237, 3089, 2340, 2237, 3762, 3622, 3701, 2237, 877, 4244, 2865]\n",
      "'eat me' were beautifully marked in currants. 'well, i'll eat it,' said alice, 'and if said of in much i or it i she said seemed i can the much\n",
      "said of in much i or it i she said seemed i can the much\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "generated_text = []\n",
    "pattern = dataX[2000][:]\n",
    "\n",
    "# generate characters\n",
    "for i in range(15):\n",
    "    x = np.reshape(pattern, (1, seq_length, 1))\n",
    "    x = x / float(len(vocab))\n",
    "    prediction = generative_model.predict(x, verbose=0)\n",
    "    index = sample(prediction[0])\n",
    "    result = int_to_word[index]\n",
    "    pattern.append(index)\n",
    "    generated_text.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "    \n",
    "print(pattern)\n",
    "print(' '.join([remove_pos_tag(int_to_word[value]) for value in pattern]))\n",
    "print(' '.join([remove_pos_tag(int_to_word[value]) for value in generated_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
