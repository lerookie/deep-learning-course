{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.1.0\n",
      "Keras version: 2.0.8\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Input\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "print(\"Keras version: {}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "raw_text = open(\"./data/001ssb.txt\").read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  1607894\n",
      "Total Vocab:  53\n"
     ]
    }
   ],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  1607864\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 30\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = keras.utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 256)           264192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 53)                13621     \n",
      "=================================================================\n",
      "Total params: 803,125\n",
      "Trainable params: 803,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "inp = Input(shape=(X.shape[1], X.shape[2]))\n",
    "x = LSTM(256, return_sequences=True)(inp)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(256)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output = Dense(y.shape[1], activation ='softmax')(x)\n",
    "\n",
    "generative_model = Model(inputs=inp, outputs=output)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "generative_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "generative_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1607864/1607864 [==============================] - 1818s - loss: 2.2420  \n",
      "Epoch 2/20\n",
      "1607864/1607864 [==============================] - 1818s - loss: 1.8789  \n",
      "Epoch 3/20\n",
      "1607864/1607864 [==============================] - 1848s - loss: 1.7531  \n",
      "Epoch 4/20\n",
      "1607864/1607864 [==============================] - 1871s - loss: 1.6812  \n",
      "Epoch 5/20\n",
      "1607864/1607864 [==============================] - 1887s - loss: 1.6354  \n",
      "Epoch 6/20\n",
      "1607864/1607864 [==============================] - 1885s - loss: 1.6018  \n",
      "Epoch 7/20\n",
      "1607864/1607864 [==============================] - 1884s - loss: 1.5771  \n",
      "Epoch 8/20\n",
      "1607864/1607864 [==============================] - 1888s - loss: 1.5573  \n",
      "Epoch 9/20\n",
      "1607864/1607864 [==============================] - 1884s - loss: 1.5407  \n",
      "Epoch 10/20\n",
      "1607864/1607864 [==============================] - 1885s - loss: 1.5268  \n",
      "Epoch 11/20\n",
      "1607864/1607864 [==============================] - 1885s - loss: 1.5145  \n",
      "Epoch 12/20\n",
      "1607864/1607864 [==============================] - 1886s - loss: 1.5043  \n",
      "Epoch 13/20\n",
      "1607864/1607864 [==============================] - 1886s - loss: 1.4951  \n",
      "Epoch 14/20\n",
      "1607864/1607864 [==============================] - 1886s - loss: 1.4867  \n",
      "Epoch 15/20\n",
      "1607864/1607864 [==============================] - 1887s - loss: 1.4791  \n",
      "Epoch 16/20\n",
      "1607864/1607864 [==============================] - 1889s - loss: 1.4718  \n",
      "Epoch 17/20\n",
      "1607864/1607864 [==============================] - 1887s - loss: 1.4651  \n",
      "Epoch 18/20\n",
      "1607864/1607864 [==============================] - 1889s - loss: 1.4596  \n",
      "Epoch 19/20\n",
      "1607864/1607864 [==============================] - 1887s - loss: 1.4538  \n",
      "Epoch 20/20\n",
      "1607864/1607864 [==============================] - 1887s - loss: 1.4485  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x254a934af98>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "generative_model.fit(X, y, epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" an said. \n",
      "\"yes,\" robb agreed.  \"\n",
      "\"you all the s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ears to see the last sister beneath her belly. the cole suone was an armor, and if it seemed to the seat and he had to be the bastard for the sont, poesen of the gates and the sight of a were the boy of the stallion of the wareancers the wall before the one of a boy to the seatone of his chair with a steel in the sister something and said. \"arya thought the more than he \n",
      "thought. she was the sound of the brothers of the window that she had helped \n",
      "her that you do not be a second what i was geven than the sight of the see farter to wilterfell, and the forest had gone to the srarks to the eire. she was she spoken \n",
      "sudel. \n",
      "the nane moued with the bert to let them mee with the peace. the silver wall of the front of the certainty \n",
      "for the sinvls of his face. \n",
      "\"the spnane was a bastard than stubborn from the high lannisters of the shout hands and the girl were koowing the shadow. a suill said as a base of the black crown, and when he had been seated at the brothers of the seven\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start][:]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = generative_model.predict(x, verbose=0)\n",
    "    index = sample(np.reshape(prediction, prediction.shape[1]), 0.5)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
