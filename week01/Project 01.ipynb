{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62, 43, 81, 99, 20]\n"
     ]
    }
   ],
   "source": [
    "# Build set of numbers of remove\n",
    "remove_num = 5\n",
    "remove_list = []\n",
    "for iteration in range(remove_num):\n",
    "    rand_num = np.random.randint(0, 100)\n",
    "    if rand_num not in remove_list:\n",
    "        remove_list.append(rand_num)\n",
    "        \n",
    "print(remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1\n",
      "0  47  17\n",
      "1  13  33\n",
      "2   5  67\n",
      "3  89  85\n",
      "4  49   7\n",
      "5  39  59\n",
      "6  68  27\n",
      "7  92  97\n",
      "8  91  70\n",
      "9   7  19\n",
      "   0    1    2    3    4    5    6    7    8    9   ...   191  192  193  194  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
      "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
      "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
      "7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
      "8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
      "9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
      "\n",
      "   195  196  197  198  199  200  \n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "5  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "6  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "7  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "8  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "9  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[10 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "# Build dataset\n",
    "n_classes = 201\n",
    "dataset_size = 10000\n",
    "pairs = pd.DataFrame(np.random.randint(0, 100, size=(dataset_size, 2)))\n",
    "\n",
    "pairs = pairs[~pairs[0].isin(remove_list) & ~pairs[1].isin(remove_list)]\n",
    "\n",
    "labels = pd.DataFrame([pair[0] + pair[1] for index, pair in pairs.iterrows()])\n",
    "labels = pd.DataFrame(keras.utils.to_categorical(labels, n_classes))\n",
    "\n",
    "print(pairs[:10])\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0'], ['1', '0', '1', '1', '1', '0', '0', '0', '1', '0', '0', '1', '0', '1'], ['1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0'], ['0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '0'], ['0', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1'], ['0', '0', '1', '1', '0', '1', '1', '0', '0', '1', '0', '0', '1', '1'], ['0', '0', '0', '1', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1'], ['0', '0', '1', '1', '1', '0', '1', '0', '1', '0', '0', '1', '1', '0'], ['0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0'], ['0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '1', '0', '0', '1']]\n"
     ]
    }
   ],
   "source": [
    "# Convert integer to binary\n",
    "def convert_int_to_bin_list(num, places=7):\n",
    "    return list(format(num, '0'+str(places)+'b'))\n",
    "\n",
    "convert_int_to_bin_list(50, 7)\n",
    "\n",
    "# Format the pairs\n",
    "pairs_vectors = [convert_int_to_bin_list(pair[0]) + convert_int_to_bin_list(pair[1]) for index, pair in pairs.iterrows()]\n",
    "\n",
    "print(pairs_vectors[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition data into training set and validation set\n",
    "x_train, x_test, y_train, y_test = train_test_split(pairs_vectors, labels.values, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.005\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 14\n",
    "n_hidden = 128 \n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the input layer, hidden layers and output layer\n",
    "Inp = Input(shape=(n_input,))\n",
    "x = Inp\n",
    "for index in range(num_layers):\n",
    "    x = Dense(n_hidden, activation='relu', name = \"Dense_\" + str(index))(x)\n",
    "\n",
    "output = Dense(n_classes, activation='softmax', name = \"Outputlayer\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "Dense_0 (Dense)              (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "Outputlayer (Dense)          (None, 201)               25929     \n",
      "=================================================================\n",
      "Total params: 60,873\n",
      "Trainable params: 60,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(Inp, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set the learning rate of the model\n",
    "K.set_value(model.optimizer.lr, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7180 samples, validate on 1795 samples\n",
      "Epoch 1/100\n",
      "7180/7180 [==============================] - 1s - loss: 4.8242 - acc: 0.0180 - val_loss: 4.1774 - val_acc: 0.0279\n",
      "Epoch 2/100\n",
      "7180/7180 [==============================] - 0s - loss: 3.7189 - acc: 0.0635 - val_loss: 3.3399 - val_acc: 0.0852\n",
      "Epoch 3/100\n",
      "7180/7180 [==============================] - 0s - loss: 2.7636 - acc: 0.1728 - val_loss: 2.3653 - val_acc: 0.2245\n",
      "Epoch 4/100\n",
      "7180/7180 [==============================] - 0s - loss: 1.9496 - acc: 0.3454 - val_loss: 1.6429 - val_acc: 0.4401\n",
      "Epoch 5/100\n",
      "7180/7180 [==============================] - 0s - loss: 1.2491 - acc: 0.5727 - val_loss: 1.0079 - val_acc: 0.6607\n",
      "Epoch 6/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.7396 - acc: 0.7443 - val_loss: 0.7350 - val_acc: 0.7476\n",
      "Epoch 7/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.4815 - acc: 0.8394 - val_loss: 0.4541 - val_acc: 0.8524\n",
      "Epoch 8/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.2963 - acc: 0.9046 - val_loss: 0.3112 - val_acc: 0.9064\n",
      "Epoch 9/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.1809 - acc: 0.9497 - val_loss: 0.1687 - val_acc: 0.9526\n",
      "Epoch 10/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.1068 - acc: 0.9720 - val_loss: 0.1262 - val_acc: 0.9738\n",
      "Epoch 11/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.1415 - acc: 0.9567 - val_loss: 0.1432 - val_acc: 0.9660\n",
      "Epoch 12/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0701 - acc: 0.9804 - val_loss: 0.0958 - val_acc: 0.9822\n",
      "Epoch 13/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.1866 - acc: 0.9464 - val_loss: 0.7113 - val_acc: 0.7877\n",
      "Epoch 14/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.2592 - acc: 0.9181 - val_loss: 0.1405 - val_acc: 0.9716\n",
      "Epoch 15/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0522 - acc: 0.9864 - val_loss: 0.0609 - val_acc: 0.9916\n",
      "Epoch 16/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0213 - acc: 0.9944 - val_loss: 0.0486 - val_acc: 0.9928\n",
      "Epoch 17/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0168 - acc: 0.9971 - val_loss: 0.0653 - val_acc: 0.9889\n",
      "Epoch 18/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0124 - acc: 0.9968 - val_loss: 0.0471 - val_acc: 0.9950\n",
      "Epoch 19/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0090 - acc: 0.9987 - val_loss: 0.0519 - val_acc: 0.9933\n",
      "Epoch 20/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0575 - acc: 0.9838 - val_loss: 0.4167 - val_acc: 0.8780\n",
      "Epoch 21/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.1432 - acc: 0.9542 - val_loss: 0.1152 - val_acc: 0.9760\n",
      "Epoch 22/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0357 - acc: 0.9896 - val_loss: 0.0674 - val_acc: 0.9872\n",
      "Epoch 23/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0193 - acc: 0.9948 - val_loss: 0.0746 - val_acc: 0.9889\n",
      "Epoch 24/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0176 - acc: 0.9955 - val_loss: 0.0646 - val_acc: 0.9905\n",
      "Epoch 25/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0111 - acc: 0.9979 - val_loss: 0.0440 - val_acc: 0.9944\n",
      "Epoch 26/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0158 - acc: 0.9974 - val_loss: 0.0822 - val_acc: 0.9866\n",
      "Epoch 27/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0357 - acc: 0.9908 - val_loss: 0.3522 - val_acc: 0.9209\n",
      "Epoch 28/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.2321 - acc: 0.9344 - val_loss: 0.2215 - val_acc: 0.9376\n",
      "Epoch 29/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.1935 - acc: 0.9415 - val_loss: 0.2150 - val_acc: 0.9460\n",
      "Epoch 30/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0615 - acc: 0.9826 - val_loss: 0.0857 - val_acc: 0.9850\n",
      "Epoch 31/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0351 - acc: 0.9905 - val_loss: 0.0592 - val_acc: 0.9922\n",
      "Epoch 32/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0241 - acc: 0.9951 - val_loss: 0.0908 - val_acc: 0.9900\n",
      "Epoch 33/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0081 - acc: 0.9989 - val_loss: 0.0438 - val_acc: 0.9961\n",
      "Epoch 34/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0031 - acc: 0.9999 - val_loss: 0.0437 - val_acc: 0.9967\n",
      "Epoch 35/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0029 - acc: 0.9999 - val_loss: 0.0420 - val_acc: 0.9967\n",
      "Epoch 36/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0026 - acc: 0.9999 - val_loss: 0.0421 - val_acc: 0.9967\n",
      "Epoch 37/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0026 - acc: 0.9999 - val_loss: 0.0421 - val_acc: 0.9967\n",
      "Epoch 38/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0422 - val_acc: 0.9967\n",
      "Epoch 39/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0422 - val_acc: 0.9967\n",
      "Epoch 40/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0421 - val_acc: 0.9967\n",
      "Epoch 41/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0423 - val_acc: 0.9967\n",
      "Epoch 42/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0422 - val_acc: 0.9967\n",
      "Epoch 43/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0423 - val_acc: 0.9967\n",
      "Epoch 44/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0422 - val_acc: 0.9967\n",
      "Epoch 45/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0423 - val_acc: 0.9967\n",
      "Epoch 46/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0424 - val_acc: 0.9967\n",
      "Epoch 47/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0424 - val_acc: 0.9967\n",
      "Epoch 48/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0425 - val_acc: 0.9967\n",
      "Epoch 49/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0425 - val_acc: 0.9961\n",
      "Epoch 50/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0424 - val_acc: 0.9961\n",
      "Epoch 51/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0426 - val_acc: 0.9961\n",
      "Epoch 52/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0426 - val_acc: 0.9961\n",
      "Epoch 53/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0426 - val_acc: 0.9961\n",
      "Epoch 54/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0427 - val_acc: 0.9961\n",
      "Epoch 55/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0427 - val_acc: 0.9961\n",
      "Epoch 56/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0427 - val_acc: 0.9961\n",
      "Epoch 57/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0428 - val_acc: 0.9961\n",
      "Epoch 58/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0428 - val_acc: 0.9961\n",
      "Epoch 59/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0429 - val_acc: 0.9961\n",
      "Epoch 60/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0429 - val_acc: 0.9961\n",
      "Epoch 61/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0430 - val_acc: 0.9961\n",
      "Epoch 62/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0430 - val_acc: 0.9961\n",
      "Epoch 63/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0431 - val_acc: 0.9961\n",
      "Epoch 64/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0432 - val_acc: 0.9961\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0432 - val_acc: 0.9961\n",
      "Epoch 66/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0433 - val_acc: 0.9961\n",
      "Epoch 67/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0433 - val_acc: 0.9961\n",
      "Epoch 68/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0433 - val_acc: 0.9961\n",
      "Epoch 69/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0433 - val_acc: 0.9961\n",
      "Epoch 70/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0433 - val_acc: 0.9961\n",
      "Epoch 71/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0434 - val_acc: 0.9961\n",
      "Epoch 72/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0434 - val_acc: 0.9961\n",
      "Epoch 73/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0434 - val_acc: 0.9961\n",
      "Epoch 74/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0434 - val_acc: 0.9961\n",
      "Epoch 75/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0435 - val_acc: 0.9961\n",
      "Epoch 76/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0435 - val_acc: 0.9961\n",
      "Epoch 77/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0435 - val_acc: 0.9961\n",
      "Epoch 78/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0435 - val_acc: 0.9961\n",
      "Epoch 79/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0436 - val_acc: 0.9961\n",
      "Epoch 80/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0436 - val_acc: 0.9961\n",
      "Epoch 81/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0436 - val_acc: 0.9961\n",
      "Epoch 82/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0436 - val_acc: 0.9961\n",
      "Epoch 83/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0436 - val_acc: 0.9961\n",
      "Epoch 84/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0437 - val_acc: 0.9961\n",
      "Epoch 85/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0437 - val_acc: 0.9961\n",
      "Epoch 86/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0437 - val_acc: 0.9961\n",
      "Epoch 87/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0438 - val_acc: 0.9961\n",
      "Epoch 88/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0438 - val_acc: 0.9961\n",
      "Epoch 89/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0438 - val_acc: 0.9961\n",
      "Epoch 90/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0439 - val_acc: 0.9961\n",
      "Epoch 91/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0439 - val_acc: 0.9961\n",
      "Epoch 92/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0439 - val_acc: 0.9961\n",
      "Epoch 93/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0439 - val_acc: 0.9961\n",
      "Epoch 94/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0440 - val_acc: 0.9961\n",
      "Epoch 95/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0440 - val_acc: 0.9961\n",
      "Epoch 96/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0440 - val_acc: 0.9961\n",
      "Epoch 97/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0440 - val_acc: 0.9961\n",
      "Epoch 98/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0441 - val_acc: 0.9961\n",
      "Epoch 99/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0441 - val_acc: 0.9961\n",
      "Epoch 100/100\n",
      "7180/7180 [==============================] - 0s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0442 - val_acc: 0.9961\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=training_epochs,\n",
    "                    verbose=1, # This is for what we want it to display out as it trains \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f71f4cc77f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the model accuracy across epochs\n",
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)\n",
    "    \n",
    "plot_train(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1\n",
      "0  62  4\n",
      "1  43  3\n",
      "[0    66\n",
      "1    46\n",
      "dtype: int64, 0    66\n",
      "1    46\n",
      "dtype: int64]\n",
      "[66, 46]\n"
     ]
    }
   ],
   "source": [
    "predict_pairs = [(62, 4), (43, 3)]\n",
    "predict_pairs = pd.DataFrame.from_records(predict_pairs)\n",
    "print(predict_pairs)\n",
    "\n",
    "#predict_pairs = pd.DataFrame(np.random.randint(0, 100, size=(5, 2)))\n",
    "\n",
    "predict_pairs_vectors = [convert_int_to_bin_list(pair[0]) + convert_int_to_bin_list(pair[1]) for index, pair in predict_pairs.iterrows()]\n",
    "\n",
    "prediction = model.predict(predict_pairs_vectors)\n",
    "\n",
    "print([predict_pairs[0] + predict_pairs[1] for pair in predict_pairs])\n",
    "\n",
    "print([np.argmax(array) for array in prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
